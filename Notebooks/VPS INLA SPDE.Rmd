---
title: "Point Process in INLA using SPDE"
output:
  html_document:
    df_print: paged
bibliography: references.bib
---

## Introduction

I've previously modeled the sturgeon VPS data as a point process by aggregating the different positions into a grid. This is apparently the main way to do it: either using a grid, or some polygon boundaries, or something like that. We could also aggregate things using the habitat polygons themselves, but I don't believe that we're interested in how bottom type polygon A differs from bottom type polygon B, more about how what's in those polygons attracts or disperses sturgeon.

The way that INLA is famous for, however, is taking the area of interest, creating a mesh, and using a stochastic partial differential equation (SPDE) to model the spatial effect as a continuous surface. Don't ask me what, exactly, an SPDE is -- I have no idea -- just know that it exists. I'm mostly following along with the examples in [this book chapter.](https://becarioprecario.bitbucket.io/spde-gitbook/ch-intro.html#sec:mesh)

We'll begin as before, by loading up the packages and pulling in our data:

```{r}
library(ggplot2); library(patchwork); library(dplyr); library(sf); library(lwgeom)
library(INLA)

positions <- data.table::fread(file.path('p:/obrien/biotelemetry/marshyhope/vps',
                                         'VPS-NanticokeRiver-Brookview-01-Results-20210106',
                                         'positions',
                                         'all-calc-positions.csv'),
                               
                               # this just applies base::tolower to the column names
                               col.names = tolower)


## Fish positions
fish <- positions %>%
  filter(grepl('^\\d', transmitter))
fish <- fish %>% 
  filter(hpe <= quantile(fish$hpe, 0.9, na.rm = T)) %>%
  st_as_sf(coords = c('lon', 'lat'),
           crs = 4326,
           remove = F)

## Import Marshyhope shape (previously cropped to the above fish detections)
mh_shape <- st_read('data/derived/mhclip_base2020vpsfish.gpkg') %>% 
  st_zm()

## Import habitat polygons that intersect with the mh_shape polygon
habitat <- st_read('data/raw/2015 Atlantic Sturgeon Habitat Geodatabase Nanticoke and Tributaries 01132016.gdb',
                   layer = 'RiverBed_Habitat_Polygons_CMECS_SC_01132016',
                   wkt_filter = st_as_text(st_geometry(mh_shape))) %>%
  
  # order bottom type from gravel to to sand to mud
  mutate(Group = ifelse(SubGroup == '<Null>', Group_, SubGroup),
         Group = factor(Group,
                        ordered = T,
                        levels = c('Sandy_Gravel',
                                   'Sand',
                                   'Muddy_Sand',
                                   'Sandy_Clay',
                                   'Sandy_Mud',
                                   'Mud',
                                   'Unclassified'))) %>% 
  # Classify anything in the Marshyhope not classified in habitat as "Unclassified"
  st_intersection(mh_shape) %>% 
  select(Group) %>% 
  rbind(
    st_sym_difference(st_union(habitat), mh_shape) %>% 
      st_as_sf() %>% 
      rename(Shape = x) %>% 
      mutate(Group = 'Unclassified') 
  )

## Reproject fish detections into the same CRS as the shapefiles and conduct
##    point-in-polygon analysis
fish <- fish %>% 
  st_transform(st_crs(habitat)) %>% 
  st_intersection(habitat)
```

## Create INLA mesh

Now we need to create a mesh using `inla.mesh.2d`. I'll be honest with you here: there are a whole lot of options that are extremely finicky and dependent on the scale of the shapefile. It seems like I'm not the only one who things so, as there's a built-in Shiny app that can be called up using `meshbuilder()`. In order to use this, all of our spatial data needs to be converted from `sf` to `sp` classes. Luckily `sf` has a built-in function for that.

```{r}
# Convert Marshyhope to SpatialDataFrame
mh_sp <- as_Spatial(mh_shape)

# Convert to mesh segments recognizable by INLA
mh_sp <- inla.sp2segment(mh_sp)
```

The next step opens a Shiny app; I'm not going to run it since this is intended to be a static document, but the output of `meshbuilder` (everything below "Generated by meshbuilder()") is below.

```{r, eval=-1}
meshbuilder()

## Generated by meshbuilder()

## Build boundary information:
## (fmesher supports SpatialPolygons, but this app is not (yet) intelligent enough for that.)

## Build the mesh:
mesh <- inla.mesh.2d(boundary=mh_sp,
                     max.edge=c(30, 153),
                     min.angle=c(30, 21),
                     max.n=c(48000, 16000), ## Safeguard against large meshes.
                     max.n.strict=c(128000, 128000), ## Don't build a huge mesh!
                     cutoff=10, ## Filter away adjacent points.
                     offset=c(1, 135)) ## Offset for extra boundaries, if needed.

## Plot the mesh:
plot(mesh)
```

The arguments to `inla.mesh.2d` are:

-   *boundary*: this can be a list denoting the inner and outer boundaries of the triangulation. Here, the outer boundary was created by the offset argument and the inner boundary is the Marshyhope outline.

-   *max.edge*: maximum triangle side length. First value is in reference to those in the inner boundary and second to the outer boundary

-   *min.angle*: smallest triangle angle. First value is in reference to those in the inner boundary and second to the outer boundary

-   *max.n*: maximum number of vertices. These values are added by default in `meshbulder`.

-   *max.n.strict*: unsure about this one, as it apparently overrides `max.n` and `min.angle`, but is provided by default in `meshbuilder`

-   *cutoff*: any points closer than this are considered as one point. Here, units are in meters, so no vertex will be less than 20 m from another vertex.

-   *offset*: this is how much of a buffer you want

Next, we need to set up that stochastic partial differential equation. Here, priors are used. I don't understand why, really, but I'm following along.

## Create SPDE

```{r}
spde <- inla.spde2.pcmatern(mesh=mesh,
                            prior.range=c(50, 0.5),
                            prior.sigma=c(5, 0.5))
```

## Get the right weights

According to Chapter 4 of @krainski2018:

> The SPDE approach for point pattern analysis defines the model at the nodes of the mesh. To fit the log-Cox point process model, these points are considered as integration points. The method in Simpson et al. ([2016](https://becarioprecario.bitbucket.io/spde-gitbook/ch-lcox.html#ref-simpsonetal:2016)) defines the expected number of events to be proportional to the area around the node (the areas of the polygons in the dual mesh). This means that at the nodes of the mesh with larger triangles, there are also larger expected values.

So, basically, (I think) that this means that we need to find what the area around each vertex of the mesh is, and then what portion of that area is inside of the Marshyhope. Polygons in the mesh will be weighted by this proportion. The vertices of the mesh are stored in `mesh$loc`. We'll turn that into an `sf` object and use Voronoi tessellation to create polygons around the vertices. Voronoi tessellation draws polygons around each point so that the boundaries of the polygons are halfway between the two nearest points.

```{r}
mesh_sf <- mesh$loc[, 1:2] %>% 
  # convert to sf class
  data.frame() %>% 
  st_as_sf(coords = c('X1', 'X2'),
           crs = st_crs(habitat)) %>% 
  
    # combine separate POINTs into one MULTIPOINT
  st_combine()

mesh_vor <- mesh_sf %>% 
  # Conduct Voronoi tessellation
  st_voronoi() %>%
  st_collection_extract()
  
plot(mesh_vor)
```

This kind of goes off into infinity somewhere, so we're going to use the boundaries of the original mesh to crop it.

```{r}
mesh_vor <- mesh_sf %>%
  st_convex_hull() %>% 
  st_intersection(mesh_vor, .)

plot(mesh_vor)
plot(mesh_sf, add = T, cex = 0.5, col = 'blue')
```

You can see there that the boundary of each polygon is halfway between its two nearest points. Now, we need to calculate the area of each polygon that falls within the Marshyhope.

```{r}
plot(mesh_vor)
plot(st_geometry(mh_shape), add = T, border = 'red')

mesh_vor <- mesh_vor %>%
  st_as_sf() %>% 
  mutate(wt = ifelse(
    # If the polygon touches the Marshyhope shape...
    st_intersects(., mh_shape, sparse = F),
    # ...calculate the area of the polygon within the Marshyhope shape...
    st_area(st_intersection(., st_geometry(mh_shape))),
    # Else, the area is zero.
                     0),
    
    # Convert all of those areas from a "units" to a "numeric" class
    wt = as.numeric(wt))

ggplot() +
  geom_sf(data = mesh_vor, aes(fill = wt)) +
  geom_sf(data = mh_shape, fill = NA, color = 'white') +
  scale_fill_viridis_c()
```

## Spatial effect only

### Apply the weights

Continuing to follow chapter 4 of @krainski2018,

> We augment the vector of ones for the observations (representing the points) with a sequence of zeros (representing the mesh nodes):

```{r}
y.pp <- rep(0:1, c(mesh$n, nrow(fish)))
```

This makes a vector of zeroes and ones, where the number of zeroes is equal to the number of mesh vertices (`mesh$n`) and the number of ones is equal to the number of observations (`nrow(fish)`; our number of positions).

> The exposure vector can be defined as:

```{r}
e.pp <- c(mesh_vor$wt, rep(0, nrow(fish))) 
```

This concatenates the vertex weights (that we just created based on the area of Voronoi polygons within the Marshyhope shapefile) with a vector of zeroes as long as the number of positions we recorded. I don't quite understand this fully. I believe that the "exposure" they reference is a different name for the offset of the model. In this case, the mesh vertices will be weighted according to Voronoi area within the Marshyhope shapefile and observations will be weighted as zero. I think this is because we aren't trying to use positions exactly where they occurred (the observations), but aggregated to some area (the weights).

### Projector grid

INLA is kind of weird in the way that if we want to make predictions, we need to tell it that up front. So, we need to make a "projector grid". This is a grid onto which predictions will be projected -- it'll be passed to argument `A` in the call to `inla`.

> The projection matrix is defined in two steps. For the integration points this is just a diagonal matrix because these locations are just the mesh vertices:

```{r}
imat <- Diagonal(mesh$n, rep(mesh$n))
```

> For the observed points, another projection matrix is defined:

```{r}
lmat <- inla.spde.make.A(mesh, loc = st_coordinates(fish))
```

> The entire projection matrix is:

```{r}
A.pp <- rbind(imat, lmat)
```

### Make the stack

For certain types of models, we need to set up a "stack". I'm not really sure why, and it doesn't make sense to me at the moment, but I'm pretty sure it happens when there are some complicated effects that are going to be fitted.

> We set up the data stack as follows:

```{r}
stk.pp <- inla.stack(
  data = list(y = y.pp, # response
              e = e.pp), # offset
  A = list(1, A.pp), # projector matrix
  effects = list(
    list(b0 = rep(1, mesh$n + nrow(fish))), # intercept
    list(i = 1:mesh$n) # spatial effect
  ),
  tag = 'pp'
)
```

### Fit the model

```{r}
pp.res <- inla(y ~ 0 + b0 + f(i, model = spde), 
               family = 'poisson',
               data = inla.stack.data(stk.pp), 
               control.predictor = list(A = inla.stack.A(stk.pp),
                                        compute = T), 
               E = inla.stack.data(stk.pp)$e)
```

## Now with covariates

> The covariate values need to be included in the data and the model for inference. These values must be available at the point pattern locations and at the mesh nodes.
